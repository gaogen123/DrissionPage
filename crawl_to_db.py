from DrissionPage import ChromiumPage
import time
import database_manager
import analyze_reviews
import os

def crawl_to_db():
    # åˆå§‹åŒ–æ•°æ®åº“
    database_manager.init_db()

    # ç”¨æˆ·æä¾›çš„æ‹¼å¤šå¤šæœç´¢é“¾æ¥
    url = "https://mobile.pinduoduo.com/search_result.html?search_key=%E5%A6%88%E5%92%AA%E5%8C%85&search_type=goods&source=index&options=3&search_met_track=manual&refer_page_el_sn=99884&refer_page_name=search_result&refer_page_id=10015_1768376320960_usqkfxqhwf&refer_page_sn=10015"
    
    page = ChromiumPage()
    print(f"ğŸš€ æ­£åœ¨æ‰“å¼€æ‹¼å¤šå¤šæœç´¢é¡µ...")
    page.get(url)
    
    print("â³ ç­‰å¾…é¡µé¢åŠ è½½...")
    time.sleep(3)
    
    # å°è¯•å®šä½å•†å“åˆ—è¡¨
    print("ğŸ”„ æ­£åœ¨åˆ†æå•†å“åˆ—è¡¨...")
    
    # ä½¿ç”¨ç”¨æˆ·æä¾›çš„åˆ—è¡¨ class: _3glhOBhU
    product_cards = page.eles('._3glhOBhU')
    
    if product_cards:
        print(f"ğŸ‰ è¯†åˆ«åˆ° {len(product_cards)} ä¸ªå¯èƒ½çš„å•†å“ï¼Œå‡†å¤‡é‡‡é›†å‰ 20 ä¸ª...")
        
        # é‡‡é›†å‰ 20 ä¸ªå•†å“ (å¦‚æœä¸è¶³ 20 ä¸ªåˆ™é‡‡é›†æ‰€æœ‰)
        target_count = 20
        count_to_crawl = min(len(product_cards), target_count)
        
        for i in range(count_to_crawl):
            print(f"\nğŸš€ [ç¬¬ {i+1} ä¸ªå•†å“] å‡†å¤‡å¤„ç†...")
            
            try:
                # é‡æ–°è·å–å¡ç‰‡åˆ—è¡¨ï¼ˆå› ä¸ºDOMæ›´æ–°ï¼‰
                current_cards = page.eles('._3glhOBhU')
                if not current_cards or i >= len(current_cards):
                    print(f"    âš ï¸ æ— æ³•è·å–ç¬¬ {i+1} ä¸ªå¡ç‰‡")
                    break
                
                card = current_cards[i]
                current_url = page.url
                
                # ç‚¹å‡»è¿›å…¥è¯¦æƒ…
                card.click()
                time.sleep(3) 
                
                if page.url == current_url:
                    print("    âš ï¸ ç‚¹å‡»æœªè·³è½¬")
                    continue
                    
                print(f"    ğŸ“„ è¿›å…¥è¯¦æƒ…é¡µ: {page.title[:20]}...")
                
                # è·å–æ ‡é¢˜
                title_ele = page.ele('.Vrv3bF_E', timeout=5)
                title = title_ele.text if title_ele else "æœªçŸ¥å•†å“"
                print(f"    ğŸ“Œ [å•†å“æ ‡é¢˜]: {title}")
                
                # è§£æ platform_goods_id
                from urllib.parse import urlparse, parse_qs
                parsed_url = urlparse(page.url)
                query_params = parse_qs(parsed_url.query)
                platform_id = query_params.get('goods_id', [None])[0]
                if platform_id:
                    print(f"    ğŸ†” [å•†å“ID]: {platform_id}")
                else:
                    print(f"    âš ï¸ æœªä»URLè§£æåˆ° goods_id")
                
                # å°è¯•ç‚¹å‡»â€œæŸ¥çœ‹æ›´å¤šè¯„ä»·â€
                print("    ğŸ‘‰ å°è¯•ç‚¹å‡»â€œæŸ¥çœ‹å…¨éƒ¨è¯„ä»·â€...")
                view_more_btn = page.ele('.IpR_6z4r')
                has_clicked_reviews = False
                
                if view_more_btn:
                    view_more_btn.click()
                    time.sleep(2)
                    print("    ğŸ“„ å·²è¿›å…¥è¯„ä»·åˆ—è¡¨é¡µ")
                    has_clicked_reviews = True
                else:
                    print("    âš ï¸ æœªæ‰¾åˆ°â€œæŸ¥çœ‹å…¨éƒ¨è¯„ä»·â€æŒ‰é’®ï¼Œä»…æŠ“å–å½“å‰é¡µè¯„ä»·")
                    page.scroll.down(300)

                # --- æ— è®ºæ˜¯å¦æœ‰è¯„è®ºï¼Œå…ˆä¿å­˜å•†å“ä¿¡æ¯ ---
                print(f"    ğŸ’¾ ä¿å­˜å•†å“ä¿¡æ¯: {title[:20]}...")
                goods_id = database_manager.save_product(title, page.url, platform_id)
                
                # æ”¶é›†è¯„è®º
                collected_reviews = []
                
                if has_clicked_reviews:
                    print("    ğŸ”„ æ­£åœ¨æ»šåŠ¨åŠ è½½æ›´å¤šè¯„è®º (æœ€å¤§ 20 æ¬¡)...")
                    for _ in range(20): 
                        page.scroll.down(1000)
                        time.sleep(0.5)
                    
                    reviews_elements = page.eles('.QznBag3Z')
                else:
                    reviews_elements = page.eles('.BMUTYZnz')
                
                if reviews_elements:
                    print(f"    âœ… æŠ“å–åˆ° {len(reviews_elements)} æ¡è¯„è®ºï¼Œæ­£åœ¨æå–æ–‡æœ¬...")
                    for r in reviews_elements:
                        text = r.text.replace('\n', ' ').strip()
                        if text:
                            collected_reviews.append(text)
                            
                    if collected_reviews:
                        # è¿‡æ»¤æ— æ•ˆè¯„è®º
                        filtered_reviews = [
                            r for r in collected_reviews 
                            if "è¯¥ç”¨æˆ·è§‰å¾—å•†å“å¾ˆå¥½ï¼Œç»™å‡ºäº†5æ˜Ÿå¥½è¯„" not in r and len(r) > 2
                        ]
                        
                        if filtered_reviews:
                            # ä¿å­˜è¯„è®º
                            database_manager.save_reviews(goods_id, filtered_reviews, platform_id)
                            print(f"    âœ… å®é™…å…¥åº“: {len(filtered_reviews)} æ¡ (å·²è¿‡æ»¤æ— æ•ˆè¯„è®º)")
                        else:
                            print("    âš ï¸ ç»è¿‡è¿‡æ»¤åæ— æœ‰æ•ˆè¯„è®º")
                    else:
                        print("    âš ï¸ è™½æ‰¾åˆ°å…ƒç´ ä½†æ— æ–‡æœ¬å†…å®¹")
                else:
                    print(f"    âŒ æœªæ‰¾åˆ°è¯„è®º")
                
                # åé€€
                print("    ğŸ”™ åé€€...")
                page.back()
                if has_clicked_reviews:
                    time.sleep(1)
                    page.back()
                
                time.sleep(3) # ç­‰å¾…æœç´¢é¡µé‡æ–°æ¸²æŸ“
                
            except Exception as e:
                print(f"    âŒ æ“ä½œå¤±è´¥: {e}")
                if "search_result" not in page.url:
                    page.back()
                    time.sleep(3)
    
    # é‡‡é›†å®Œæˆï¼Œå¯åŠ¨åˆ†æ
    print("\n" + "="*50)
    print("ğŸ‰ é‡‡é›†ä»»åŠ¡å®Œæˆï¼Œå³å°†å¼€å§‹ DeepSeek èšåˆåˆ†æ...")
    print("="*50 + "\n")
    analyze_reviews.main()

if __name__ == "__main__":
    crawl_to_db()
