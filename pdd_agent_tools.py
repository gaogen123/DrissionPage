from DrissionPage import ChromiumPage
import time
import urllib.parse
import os
import requests
import shutil

def crawl_pinduoduo(keyword: str, limit: int = 2, enable_download: bool = False) -> str:
    """
    Crawls Pinduoduo search results for a given keyword.
    
    Args:
        keyword: Search keyword.
        limit: Number of items to crawl.
        enable_download: Whether to download images.
        
    Returns:
        A string summary of the crawled items.
    """
    
    # æ„é€ æœç´¢è¿æ¥
    base_url = "https://mobile.pinduoduo.com/search_result.html"
    params = {
        "search_key": keyword,
        "search_type": "goods",
        "source": "index",
        "options": "3",
        "search_met_track": "manual"
    }
    query_string = urllib.parse.urlencode(params)
    url = f"{base_url}?{query_string}"
    
    page = ChromiumPage()
    print(f"ğŸš€ [Agent] æ­£åœ¨æ‰“å¼€æ‹¼å¤šå¤šæœç´¢é¡µ: {keyword}")
    page.get(url)
    
    print("â³ [Agent] ç­‰å¾…é¡µé¢åŠ è½½...")
    time.sleep(3)
    
    # å°è¯•å®šä½å•†å“åˆ—è¡¨
    print("ğŸ”„ [Agent] æ­£åœ¨åˆ†æå•†å“åˆ—è¡¨...")
    
    results_summary = []
    
    # è·å–å•†å“å¡ç‰‡
    product_cards = page.eles('._3glhOBhU')
    
    # è¿‡æ»¤æ— æ•ˆå¡ç‰‡
    valid_cards = []
    if product_cards:
        for card in product_cards:
            try:
                if card.rect.size[0] > 0 and card.rect.size[1] > 0:
                    valid_cards.append(card)
            except:
                pass
    product_cards = valid_cards
    
    # å¦‚æœæ²¡æ‰¾åˆ°ï¼Œå°è¯•æ¨¡ç³Š
    if not product_cards:
        print("âš ï¸ [Agent] æ ‡å‡† class æœªæ‰¾åˆ°ï¼Œå°è¯• tag:img ç­–ç•¥...")
        candidates = page.eles('tag:img')
        for img in candidates:
            try:
                if img.rect.size[0] > 50 and img.rect.size[1] > 50:
                    card = img.parent(2)
                    if card:
                        product_cards.append(card)
            except:
                pass
        # å»é‡
        product_cards = list(set(product_cards)) if isinstance(product_cards, list) else list(product_cards)
        try:
            product_cards.sort(key=lambda x: x.rect.top)
        except:
            pass

    if not product_cards:
        return f"æœªèƒ½æ‰¾åˆ°å…³äº '{keyword}' çš„å•†å“åˆ—è¡¨ã€‚"

    print(f"ğŸ‰ [Agent] è¯†åˆ«åˆ° {len(product_cards)} ä¸ªå¯èƒ½çš„å•†å“ï¼Œå‡†å¤‡é‡‡é›†å‰ {limit} ä¸ª...")
    
    count = 0
    for i in range(len(product_cards)):
        if count >= limit:
            break
            
        print(f"\nğŸš€ [Agent] å¤„ç†ç¬¬ {count+1}/{limit} ä¸ªå•†å“...")
        
        try:
            # é‡æ–°è·å–åˆ—è¡¨ä»¥é˜²å¤±æ•ˆ
            current_cards = page.eles('._3glhOBhU')
            if not current_cards or i >= len(current_cards):
                print(f"    âš ï¸ æ— æ³•è·å–ç¬¬ {i+1} ä¸ªå¡ç‰‡")
                continue
            
            card = current_cards[i]
            
            # è®°å½• URL ç”¨äºæ£€æµ‹è·³è½¬
            search_page_url = page.url
            
            # ç‚¹å‡»
            card.click()
            time.sleep(3)
            
            if page.url == search_page_url:
                print("    âš ï¸ ç‚¹å‡»æœªè·³è½¬")
                continue
                
            print(f"    ğŸ“„ è¿›å…¥è¯¦æƒ…é¡µ: {page.title[:20]}...")
            
            # æå–æ•°æ®
            item_data = {}
            
            # 1. æ ‡é¢˜
            title_ele = page.ele('.Vrv3bF_E', timeout=5)
            title = title_ele.text if title_ele else "æœªçŸ¥æ ‡é¢˜"
            item_data['title'] = title
            print(f"    ğŸ“Œ [æ ‡é¢˜]: {title}")
            
            # 2. ä»·æ ¼
            price_ele = page.ele('.kxqW0mMz', timeout=2)
            price = price_ele.text if price_ele else "æœªçŸ¥ä»·æ ¼"
            item_data['price'] = price
            print(f"    ğŸ’° [ä»·æ ¼]: {price}")
            
            # 3. è¯¦æƒ…
            detail_ele = page.ele('.jvsKAdEs', timeout=2)
            if detail_ele:
                raw_text = detail_ele.text
                parts = [p.strip() for p in raw_text.split('\n') if p.strip()]
                formatted_pairs = []
                for k in range(0, len(parts) - 1, 2):
                    formatted_pairs.append(f"{parts[k]}:{parts[k+1]}")
                detail_str = " ".join(formatted_pairs)
                item_data['details'] = detail_str
                print(f"    ğŸ“ [è¯¦æƒ…]: {detail_str}")
            else:
                item_data['details'] = "æ— è¯¦æƒ…"
                print("    âš ï¸ æœªæ‰¾åˆ°è¯¦æƒ…")
            
            # 4. å›¾ç‰‡ä¸‹è½½ (å¦‚æœ enable_download ä¸º True)
            if enable_download:
                print("    ğŸ–¼ï¸ æ­£åœ¨æå–å›¾ç‰‡...")
                img_containers = page.eles('.PPuOGFfM')
                if img_containers:
                    save_dir = f"pdd_images/{keyword}_{count+1}"
                    if not os.path.exists(save_dir):
                        os.makedirs(save_dir, exist_ok=True)
                    
                    downloaded_count = 0
                    for idx, container in enumerate(img_containers):
                        img = container.ele('tag:img')
                        if img:
                            src = img.link or img.attr('data-src') or img.attr('data-url')
                            if src:
                                if src.startswith('//'): src = 'https:' + src
                                try:
                                    res = requests.get(src, timeout=5)
                                    if res.status_code == 200:
                                        with open(f"{save_dir}/{idx}.jpg", 'wb') as f:
                                            f.write(res.content)
                                        downloaded_count += 1
                                except:
                                    pass
                    print(f"      âœ… å·²ä¸‹è½½ {downloaded_count} å¼ å›¾ç‰‡åˆ° {save_dir}")
                    item_data['images_path'] = save_dir
            
            # æ ¼å¼åŒ–ç»“æœç”¨äºè¿”å›
            summary_entry = (
                f"å•†å“ {count+1}:\n"
                f"  æ ‡é¢˜: {item_data['title']}\n"
                f"  ä»·æ ¼: {item_data['price']}\n"
                f"  è¯¦æƒ…: {item_data['details']}\n"
            )
            results_summary.append(summary_entry)
            
            count += 1
            
            # åé€€
            print("    ğŸ”™ åé€€...")
            page.back()
            time.sleep(2)
            
        except Exception as e:
            print(f"    âŒ å¤„ç†å‡ºé”™: {e}")
            if "search_result" not in page.url:
                page.back()
                time.sleep(3)
    
    return "\n".join(results_summary)

if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    print(crawl_pinduoduo("å¦ˆå’ªåŒ…", limit=1))
